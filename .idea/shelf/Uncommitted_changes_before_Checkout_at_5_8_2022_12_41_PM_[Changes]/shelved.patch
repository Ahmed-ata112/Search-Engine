Index: Core/src/main/java/org/mpack/Indexer.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package org.mpack;\r\n\r\nimport ca.rmen.porterstemmer.PorterStemmer;\r\n\r\nimport org.apache.commons.lang3.StringUtils;\r\n\r\nimport java.io.File;\r\nimport java.io.FileNotFoundException;\r\nimport java.util.*;\r\n\r\nimport org.jetbrains.annotations.NotNull;\r\nimport org.jsoup.Jsoup;\r\nimport org.jsoup.nodes.Document;\r\nimport org.springframework.data.util.Pair;\r\n\r\nimport java.util.ArrayList;\r\nimport java.util.List;\r\n\r\npublic class Indexer {\r\n\r\n    static final MongodbIndexer mongoDB = new MongodbIndexer();\r\n\r\n    HashMap<String, HashMap<String, WordInfo>> invertedFile;\r\n\r\n    HashMap<String, Set<String>> equivalentStems = new HashMap<>();\r\n\r\n    long documentsCount;\r\n\r\n    public static void main(String[] arg) throws FileNotFoundException {\r\n\r\n        Indexer obj = new Indexer();\r\n        obj.documentsCount = mongoDB.getDocCount();\r\n        //get crawled docs\r\n\r\n        HashMap<String, Pair<Float, String>> htmlDocs = mongoDB.getHTML();\r\n        ///      url     body\r\n\r\n        ArrayList<HashMap<String, Integer>> docFlags;\r\n        ArrayList<String> title;\r\n        ArrayList<String> header;\r\n        HashMap<Character, List<String>> stopWords = obj.constructStopWords();\r\n\r\n\r\n        for (Map.Entry<String, Pair<Float, String>> set : htmlDocs.entrySet()) {\r\n            docFlags = new ArrayList<>(2);\r\n            for (int i = 0; i < 2; i++)\r\n                docFlags.add(i, new HashMap<>());\r\n            title = new ArrayList<>();\r\n            header = new ArrayList<>();\r\n\r\n\r\n            Pair<String, List<String>> parsedHTML = obj.parseHTML(set.getValue().getSecond(), title, header);\r\n\r\n            obj.extractFlags(docFlags, title, header);\r\n            List<String> tokens = obj.extractWords(parsedHTML.getFirst());\r\n            mongoDB.StoreTextUrl(parsedHTML.getSecond(), set.getKey());\r\n            obj.removeStopWords(tokens, stopWords);\r\n            obj.stemWord(tokens);\r\n\r\n            obj.invertedFile(set.getKey(), tokens, docFlags, set.getValue().getFirst());\r\n\r\n        }\r\n\r\n        //////////////////////////////test ranker:\r\n\r\n        Ranker ranker = new Ranker();\r\n        HashMap<Integer, ArrayList<String>> retDoc = new HashMap<>();\r\n        ArrayList<String> words = new ArrayList<String>();\r\n        int i = 0;\r\n        for (Map.Entry<String, HashMap<String, WordInfo>> entry : obj.invertedFile.entrySet()) {\r\n            words.add(entry.getKey());\r\n            i++;\r\n            if (i == 5) break;\r\n        }\r\n        retDoc.put(0, words);\r\n        retDoc.put(1, new ArrayList<>());\r\n        //System.out.println(ranker.ranker(retDoc));\r\n\r\n///////////////////////////////////////////////////////////////\r\n        mongoDB.StoreStemming(obj.equivalentStems);\r\n        mongoDB.insertInvertedFile(obj.invertedFile, obj.documentsCount);\r\n\r\n\r\n    }\r\n\r\n    public Indexer() {\r\n\r\n        invertedFile = new HashMap<>();\r\n\r\n        // id     documents  id       fields & values <TF, POSITION, FLAG>\r\n    }\r\n\r\n    //read the stop words\r\n    public static @NotNull HashMap<Character, List<String>> constructStopWords() throws FileNotFoundException {\r\n        //read the file contains stop words\r\n        File file = new File(\".\\\\attaches\\\\stopwords.txt\");\r\n\r\n        Scanner scan = new Scanner(file);\r\n\r\n\r\n        HashMap<Character, List<String>> stopWords = new HashMap<>();\r\n        //List<String> stopWords = new ArrayList<String>();\r\n\r\n        while (scan.hasNextLine()) {\r\n            //append it to the list\r\n            String stopWord = scan.nextLine();\r\n            Character key = stopWord.charAt(0);\r\n            if (!stopWords.containsKey(key)) {\r\n                stopWords.put(key, new ArrayList<String>(Collections.singleton(stopWord)));\r\n            } else\r\n                stopWords.get(key).add(stopWord);\r\n\r\n        }\r\n\r\n        return stopWords;\r\n    }\r\n\r\n    Pair<String, List<String>> parseHTML(String HTMLText, ArrayList<String> title, ArrayList<String> header) {\r\n        org.jsoup.nodes.Document parsed;\r\n        parsed = Jsoup.parse(HTMLText);\r\n        if (!parsed.getElementsByTag(\"main\").isEmpty())\r\n            parsed = Jsoup.parse(parsed.getElementsByTag(\"main\").first().toString());\r\n        parsed.select(\"button\").remove();\r\n        parsed.select(\"input\").remove();\r\n\r\n        List<String> pText = parsed.getElementsByTag(\"p\").eachText();\r\n        if (parsed.getElementsByTag(\"title\").first() != null)\r\n            pText.add(0, parsed.getElementsByTag(\"title\").first().text());\r\n        else\r\n            pText.add(0, \"\");\r\n        pText.add(1, parsed.getElementsByTag(\"meta\").attr(\"description\"));\r\n        //parsed.select(\"style\").remove();\r\n        //parsed.select(\"script\").remove();\r\n\r\n        title.addAll(parsed.getElementsByTag(\"title\").eachText());\r\n        header.addAll(parsed.getElementsByTag(\"header\").eachText());\r\n        header.addAll(parsed.getElementsByTag(\"h1\").eachText());\r\n\r\n        return Pair.of(parsed.text(), pText);\r\n    }\r\n\r\n    List<String> extractWords(@NotNull String text) {\r\n        List<String> wordList = new ArrayList<>();\r\n        StringBuilder word = new StringBuilder();\r\n        char c;\r\n        for (int i = 0; i < text.length(); i++) {\r\n            c = text.charAt(i);\r\n            if (c <= 'z' && c >= 'a' || c <= 'Z' && c >= 'A' || c <= '9' && c >= '0')\r\n                word.append(c);\r\n            else {\r\n                if (word.isEmpty()) continue;\r\n                if (!StringUtils.isNumeric(word.toString()))\r\n                    wordList.add(word.toString().toLowerCase(Locale.ROOT));\r\n                word = new StringBuilder();\r\n            }\r\n        }\r\n        return wordList;\r\n    }\r\n\r\n\r\n    //remove them\r\n    public static void removeStopWords(@NotNull List<String> tokens, HashMap<Character, List<String>> stopWords) {\r\n        for (int i = 0; i < tokens.size(); i++) {\r\n\r\n            //if ((tokens.get(i).charAt(0) - 48) >= 0 || (tokens.get(i).charAt(0) - 48) <= 9)\r\n            if(stopWords.get(tokens.get(i).charAt(0)) == null)\r\n                continue;\r\n            if (stopWords.get(tokens.get(i).charAt(0)).contains(tokens.get(i).toLowerCase(Locale.ROOT)))\r\n            //if (stopWords.contains(tokens.get(i).toLowerCase(Locale.ROOT)))\r\n            {\r\n                //then remove it\r\n                tokens.remove(i);\r\n                i--;\r\n            }\r\n        }\r\n    }\r\n\r\n\r\n    private void stemWord(@NotNull List<String> tokens) {\r\n        PorterStemmer stem = new PorterStemmer();\r\n        for (String token : tokens) {\r\n            String result = stem.stemWord(token);\r\n            if (equivalentStems.containsKey(result)) {\r\n\r\n                equivalentStems.get(result).add(token);\r\n            } else {\r\n                equivalentStems.put(result, new HashSet<>());\r\n                equivalentStems.get(result).add(token);\r\n            }\r\n        }\r\n    }\r\n\r\n\r\n    private void invertedFile(String docURL, List<String> tokens, ArrayList<HashMap<String, Integer>> docFlags, float pageRank) {\r\n        for (int i = 0; i < tokens.size(); i++) {\r\n\r\n            if (invertedFile.containsKey(tokens.get(i))) {\r\n                //then go and update the positions in for this word in this doc\r\n                //but first check if the doc exists or not\r\n                if (invertedFile.get(tokens.get(i)).containsKey(docURL)) {\r\n                    //then update\r\n                    invertedFile.get(tokens.get(i)).get(docURL).addPosition(i);\r\n                    invertedFile.get(tokens.get(i)).get(docURL).incTF();\r\n                } else {\r\n                    //then create it\r\n                    WordInfo container = new WordInfo();\r\n                    container.addPosition(i);\r\n                    container.incTF();\r\n                    container.setPageRank(pageRank);\r\n                    for (short k = 0; k < docFlags.size(); k++) {\r\n                        container.setFlags(k, docFlags.get(k).getOrDefault(tokens.get(i), 0));\r\n                    }\r\n                    invertedFile.get(tokens.get(i)).put(docURL, container);\r\n                }\r\n\r\n            } else {\r\n                HashMap<String, WordInfo> docMap = new HashMap<>();\r\n                WordInfo container = new WordInfo();\r\n                container.addPosition(i);\r\n                container.incTF();\r\n                container.setPageRank(pageRank);\r\n                docMap.put(docURL, container);\r\n\r\n                for (short k = 0; k < docFlags.size(); k++) {\r\n                    container.setFlags(k, docFlags.get(k).getOrDefault(tokens.get(i), 0));\r\n                }\r\n                invertedFile.put(tokens.get(i), docMap);\r\n            }\r\n\r\n        }\r\n\r\n    }\r\n\r\n    private void extractFlags(ArrayList<HashMap<String, Integer>> docFlags, ArrayList<String> title, ArrayList<String> header) {\r\n        List<String> temp;\r\n        int k;\r\n        for (String item : title) {\r\n            temp = extractWords(item);\r\n            for (String s : temp) {\r\n                k = 0;\r\n                if (docFlags.get(0).containsKey(s)) {\r\n                    k = docFlags.get(0).get(s);\r\n                }\r\n                k++;\r\n                docFlags.get(0).put(s, k);\r\n\r\n            }\r\n        }\r\n        for (String s : header) {\r\n            temp = extractWords(s);\r\n            for (String value : temp) {\r\n                k = 0;\r\n                if (docFlags.get(1).containsKey(value)) {\r\n                    k = docFlags.get(1).get(value);\r\n                }\r\n                k++;\r\n                docFlags.get(1).put(value, k);\r\n\r\n            }\r\n        }\r\n    }\r\n\r\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Core/src/main/java/org/mpack/Indexer.java b/Core/src/main/java/org/mpack/Indexer.java
--- a/Core/src/main/java/org/mpack/Indexer.java	(revision 5d4ad9b51e9b40c6d40ddd240c943b61e124bb7d)
+++ b/Core/src/main/java/org/mpack/Indexer.java	(date 1652006489638)
@@ -61,22 +61,6 @@
 
         }
 
-        //////////////////////////////test ranker:
-
-        Ranker ranker = new Ranker();
-        HashMap<Integer, ArrayList<String>> retDoc = new HashMap<>();
-        ArrayList<String> words = new ArrayList<String>();
-        int i = 0;
-        for (Map.Entry<String, HashMap<String, WordInfo>> entry : obj.invertedFile.entrySet()) {
-            words.add(entry.getKey());
-            i++;
-            if (i == 5) break;
-        }
-        retDoc.put(0, words);
-        retDoc.put(1, new ArrayList<>());
-        //System.out.println(ranker.ranker(retDoc));
-
-///////////////////////////////////////////////////////////////
         mongoDB.StoreStemming(obj.equivalentStems);
         mongoDB.insertInvertedFile(obj.invertedFile, obj.documentsCount);
 
